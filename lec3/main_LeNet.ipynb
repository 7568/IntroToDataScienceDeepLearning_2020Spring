{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of Deep Learning for Computer Vision \n",
    "### Computer Vision and Machine Learning Research Group, Shenzhen University, 2019 Dec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Structure: LeNet  \n",
    "Dataset: cifar-10 or ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Szegedy et al., \"Going deeper with convolutions,\" 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 1-9.\n",
    "[Download Link](\n",
    "https://arxiv.org/pdf/1409.4842v1.pdf)  \n",
    "\n",
    "Code is mostly based on:  \n",
    "https://www.cnblogs.com/zhengbiqing/p/10424693.html contact：zhengbiqing 460356155@qq.com  \n",
    "\n",
    "Dataset can be downloaded from:\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "# 样本读取线程数\n",
    "WORKERS = 4\n",
    "\n",
    "# 网络参赛保存文件名\n",
    "PARAS_FN = 'cifar_lenet_params.pkl'\n",
    "\n",
    "# minist数据存放位置\n",
    "ROOT = '/home/szu-admin/local/data/cifar-10-100/cifar.10.py'\n",
    "\n",
    "# 目标函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最优结果\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络模型\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 卷积层\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 卷积层1，3通道输入，6个卷积核，核大小5*5\n",
    "            # 经过该层图像大小变为32-5+1，28*28\n",
    "            # 经2*2最大池化，图像变为14*14\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            # 卷积层2，6输入通道，16个卷积核，核大小5*5\n",
    "            # 经过该层图像变为14-5+1，10*10\n",
    "            # 经2*2最大池化，图像变为5*5\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            # 16个feature，每个feature 5*5\n",
    "            nn.Linear(16 * 5 * 5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # x.size()[0]: batch size\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "'''\n",
    "训练并测试网络\n",
    "net：网络模型\n",
    "train_data_load：训练数据集\n",
    "optimizer：优化器\n",
    "epoch：第几次训练迭代\n",
    "log_interval：训练过程中损失函数值和准确率的打印频率\n",
    "'''\n",
    "def net_train(net, train_data_load, optimizer, epoch, log_interval):\n",
    "    net.train()\n",
    "\n",
    "    begin = datetime.datetime.now()\n",
    "\n",
    "    # 样本总数\n",
    "    total = len(train_data_load.dataset)\n",
    "\n",
    "    # 样本批次训练的损失函数值的和\n",
    "    train_loss = 0\n",
    "\n",
    "    # 识别正确的样本数\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(train_data_load, 0):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = net(img)\n",
    "        loss = loss_func(outs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失值和训练样本数\n",
    "        train_loss += loss.item()\n",
    "        # total += label.size(0)\n",
    "\n",
    "        _, predicted = t.max(outs.data, 1)\n",
    "        # 累加识别正确的样本数\n",
    "        ok += (predicted == label).sum()\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            # 训练结果输出\n",
    "\n",
    "            # 损失函数均值\n",
    "            loss_mean = train_loss / (i + 1)\n",
    "\n",
    "            # 已训练的样本数\n",
    "            traind_total = (i + 1) * len(label)\n",
    "\n",
    "            # 准确度\n",
    "            acc = 100. * ok / traind_total\n",
    "\n",
    "            # 一个迭代的进度百分比\n",
    "            progress = 100. * traind_total / total\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}  Acc: {:.6f}'.format(\n",
    "                epoch, traind_total, total, progress, loss_mean, acc))\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('one epoch spend: ', end - begin)\n",
    "\n",
    "\n",
    "'''\n",
    "用测试集检查准确率\n",
    "'''\n",
    "def net_test(net, test_data_load, epoch):\n",
    "    net.eval()\n",
    "\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(test_data_load):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        outs = net(img)\n",
    "        _, pre = t.max(outs.data, 1)\n",
    "        ok += (pre == label).sum()\n",
    "\n",
    "    acc = ok.item() * 100. / (len(test_data_load.dataset))\n",
    "    print('EPOCH:{}, ACC:{}\\n'.format(epoch, acc))\n",
    "\n",
    "    global best_acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "'''\n",
    "显示数据集中一个图片\n",
    "'''\n",
    "def img_show(dataset, index):\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    show = ToPILImage()\n",
    "\n",
    "    data, label = dataset[index]\n",
    "    print('img is a ', classes[label])\n",
    "    show((data + 1) / 2).resize((100, 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='PyTorch CIFA10 LeNet Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数设置，可通过命令行设置\n",
    "bs = 64            # batch-size\n",
    "testbs = 1000      # test-batch-size\n",
    "ep = 20            # epochs \n",
    "trainlr = 0.01     # learning rate (default: 0.01)\n",
    "mm = 0.9           # SGD momentum (default: 0.9)\n",
    "logint = 100       # logging-interval\n",
    "notrain = False    # If train the Model\n",
    "savemodel = False  # For Saving the current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数值转换，ToTensor源码注释\n",
    "\"\"\"\n",
    "Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "[0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "\"\"\"\n",
    "# 归一化把[0.0, 1.0]变换为[-1,1], ([0, 1] - 0.5) / 0.5 = [-1, 1]\n",
    "transform = tv.transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "# 定义数据集\n",
    "#train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=True, transform=transform)\n",
    "train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=False, transform=transform)\n",
    "test_data = tv.datasets.CIFAR10(root=ROOT, train=False, download=False, transform=transform)\n",
    "\n",
    "train_load = t.utils.data.DataLoader(train_data, batch_size=bs, shuffle=True, num_workers=WORKERS)\n",
    "test_load = t.utils.data.DataLoader(test_data, batch_size=testbs, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faa1e4cf1d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 看一下数据中的等待分类的图片\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import sys\n",
    "#im = Image.open(train_data.data[5][0])\n",
    "im = Image.fromarray(train_data.data[5][:])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2471,  0.1765,  0.2000,  ..., -0.2863, -0.4196, -0.4039],\n",
       "          [ 0.1137,  0.1451,  0.2157,  ..., -0.0039, -0.0431, -0.3255],\n",
       "          [-0.1451, -0.2235, -0.1765,  ...,  0.0745,  0.2784, -0.2706],\n",
       "          ...,\n",
       "          [ 0.9137,  0.8824,  0.8902,  ...,  0.2235,  0.4039,  0.5686],\n",
       "          [ 0.9294,  0.9059,  0.9059,  ...,  0.2706,  0.3961,  0.5059],\n",
       "          [ 0.9294,  0.9059,  0.9137,  ...,  0.3020,  0.3569,  0.4275]],\n",
       " \n",
       "         [[-0.2000, -0.2863, -0.2549,  ..., -0.4431, -0.5059, -0.5451],\n",
       "          [-0.4118, -0.4353, -0.4039,  ..., -0.1765, -0.1294, -0.4588],\n",
       "          [-0.4745, -0.5451, -0.5373,  ..., -0.1216,  0.0353, -0.4353],\n",
       "          ...,\n",
       "          [ 0.0118, -0.0353, -0.0431,  ..., -0.6706, -0.5373, -0.4275],\n",
       "          [ 0.0431,  0.0039, -0.0039,  ..., -0.6549, -0.5608, -0.4902],\n",
       "          [ 0.0902,  0.0431,  0.0353,  ..., -0.6314, -0.6000, -0.5529]],\n",
       " \n",
       "         [[-0.2078, -0.2549, -0.2392,  ..., -0.5608, -0.5686, -0.5686],\n",
       "          [-0.4667, -0.4824, -0.4902,  ..., -0.4431, -0.2706, -0.5216],\n",
       "          [-0.4118, -0.5294, -0.5922,  ..., -0.3725, -0.1765, -0.4431],\n",
       "          ...,\n",
       "          [-0.4510, -0.4902, -0.4902,  ..., -0.8824, -0.7961, -0.7176],\n",
       "          [-0.4196, -0.4353, -0.4510,  ..., -0.8902, -0.8275, -0.7882],\n",
       "          [-0.3569, -0.3882, -0.3961,  ..., -0.8902, -0.8667, -0.8510]]]), 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[5][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define LeNet\n",
    "net = LeNet().cuda()\n",
    "# print network structure\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.298855  Acc: 12.000000\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.246532  Acc: 15.000000\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.152090  Acc: 19.000000\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.061785  Acc: 23.000000\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.986687  Acc: 26.000000\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.922227  Acc: 28.000000\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.867486  Acc: 30.000000\n",
      "one epoch spend:  0:00:02.664038\n",
      "EPOCH:1, ACC:47.4\n",
      "\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.478838  Acc: 45.000000\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.469291  Acc: 46.000000\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.450929  Acc: 46.000000\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.437912  Acc: 47.000000\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.425088  Acc: 47.000000\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.412141  Acc: 48.000000\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.400768  Acc: 49.000000\n",
      "one epoch spend:  0:00:02.711796\n",
      "EPOCH:2, ACC:55.23\n",
      "\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.265158  Acc: 54.000000\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.265101  Acc: 54.000000\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.263281  Acc: 54.000000\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.252583  Acc: 54.000000\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.241789  Acc: 55.000000\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.239358  Acc: 55.000000\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.235090  Acc: 55.000000\n",
      "one epoch spend:  0:00:02.755749\n",
      "EPOCH:3, ACC:57.12\n",
      "\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.137863  Acc: 59.000000\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.127748  Acc: 60.000000\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.132275  Acc: 59.000000\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.125395  Acc: 60.000000\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.126399  Acc: 60.000000\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.128347  Acc: 59.000000\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.125403  Acc: 59.000000\n",
      "one epoch spend:  0:00:02.724449\n",
      "EPOCH:4, ACC:60.15\n",
      "\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.067831  Acc: 62.000000\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.064459  Acc: 62.000000\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.058073  Acc: 62.000000\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.051375  Acc: 62.000000\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.051879  Acc: 62.000000\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.054708  Acc: 62.000000\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.051945  Acc: 62.000000\n",
      "one epoch spend:  0:00:02.597314\n",
      "EPOCH:5, ACC:61.62\n",
      "\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.005950  Acc: 64.000000\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.980333  Acc: 65.000000\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.989447  Acc: 64.000000\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.981628  Acc: 65.000000\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.979686  Acc: 65.000000\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.983394  Acc: 65.000000\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.985154  Acc: 64.000000\n",
      "one epoch spend:  0:00:02.611192\n",
      "EPOCH:6, ACC:62.34\n",
      "\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.923023  Acc: 67.000000\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.922102  Acc: 67.000000\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.923847  Acc: 67.000000\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.924763  Acc: 67.000000\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.924898  Acc: 67.000000\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.922702  Acc: 67.000000\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.924712  Acc: 67.000000\n",
      "one epoch spend:  0:00:02.617256\n",
      "EPOCH:7, ACC:62.61\n",
      "\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.857493  Acc: 69.000000\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.858977  Acc: 69.000000\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.870873  Acc: 69.000000\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.876269  Acc: 69.000000\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.876682  Acc: 68.000000\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.879864  Acc: 68.000000\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.881651  Acc: 68.000000\n",
      "one epoch spend:  0:00:02.629582\n",
      "EPOCH:8, ACC:64.44\n",
      "\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.818930  Acc: 70.000000\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.832625  Acc: 70.000000\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.833076  Acc: 70.000000\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.833837  Acc: 70.000000\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.838635  Acc: 70.000000\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.841537  Acc: 70.000000\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.849147  Acc: 69.000000\n",
      "one epoch spend:  0:00:02.637805\n",
      "EPOCH:9, ACC:62.28\n",
      "\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.758346  Acc: 73.000000\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.763289  Acc: 73.000000\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.776787  Acc: 72.000000\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.783089  Acc: 72.000000\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.793272  Acc: 72.000000\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.798906  Acc: 71.000000\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.800743  Acc: 71.000000\n",
      "one epoch spend:  0:00:02.626562\n",
      "EPOCH:10, ACC:63.69\n",
      "\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.730339  Acc: 74.000000\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.751282  Acc: 73.000000\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.758656  Acc: 73.000000\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.761800  Acc: 73.000000\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.765095  Acc: 73.000000\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.767224  Acc: 73.000000\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.773607  Acc: 72.000000\n",
      "one epoch spend:  0:00:02.650455\n",
      "EPOCH:11, ACC:64.81\n",
      "\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.708163  Acc: 74.000000\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.720984  Acc: 74.000000\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.720500  Acc: 74.000000\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.721840  Acc: 74.000000\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.728493  Acc: 73.000000\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.734257  Acc: 73.000000\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.742653  Acc: 73.000000\n",
      "one epoch spend:  0:00:02.710732\n",
      "EPOCH:12, ACC:64.16\n",
      "\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.657847  Acc: 77.000000\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.669377  Acc: 76.000000\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.677667  Acc: 75.000000\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.689289  Acc: 75.000000\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.698151  Acc: 75.000000\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.702283  Acc: 75.000000\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.707346  Acc: 74.000000\n",
      "one epoch spend:  0:00:02.630910\n",
      "EPOCH:13, ACC:65.81\n",
      "\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.614792  Acc: 78.000000\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.637092  Acc: 77.000000\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.654343  Acc: 76.000000\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.666883  Acc: 76.000000\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.674626  Acc: 75.000000\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.679287  Acc: 75.000000\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.685494  Acc: 75.000000\n",
      "one epoch spend:  0:00:02.645525\n",
      "EPOCH:14, ACC:64.2\n",
      "\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.625100  Acc: 78.000000\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.633599  Acc: 77.000000\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.645835  Acc: 77.000000\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.655758  Acc: 76.000000\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.664407  Acc: 76.000000\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.670688  Acc: 76.000000\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.672624  Acc: 76.000000\n",
      "one epoch spend:  0:00:02.694311\n",
      "EPOCH:15, ACC:63.9\n",
      "\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.585209  Acc: 78.000000\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.600026  Acc: 78.000000\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.620183  Acc: 77.000000\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.628285  Acc: 77.000000\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.638510  Acc: 76.000000\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.641830  Acc: 76.000000\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.646202  Acc: 76.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one epoch spend:  0:00:02.780550\n",
      "EPOCH:16, ACC:64.81\n",
      "\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.559692  Acc: 79.000000\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.572976  Acc: 79.000000\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.585830  Acc: 79.000000\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.602164  Acc: 78.000000\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.615953  Acc: 78.000000\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.625434  Acc: 77.000000\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.630156  Acc: 77.000000\n",
      "one epoch spend:  0:00:02.646793\n",
      "EPOCH:17, ACC:63.93\n",
      "\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.552167  Acc: 80.000000\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.557412  Acc: 80.000000\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.572823  Acc: 79.000000\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.589288  Acc: 79.000000\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.594543  Acc: 78.000000\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.606227  Acc: 78.000000\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.608920  Acc: 78.000000\n",
      "one epoch spend:  0:00:02.657597\n",
      "EPOCH:18, ACC:64.13\n",
      "\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.514181  Acc: 81.000000\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.530924  Acc: 80.000000\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.554638  Acc: 79.000000\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.560752  Acc: 79.000000\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.567658  Acc: 79.000000\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.582269  Acc: 79.000000\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.591920  Acc: 78.000000\n",
      "one epoch spend:  0:00:02.600028\n",
      "EPOCH:19, ACC:64.12\n",
      "\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.501215  Acc: 81.000000\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.509826  Acc: 81.000000\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.526224  Acc: 81.000000\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.535137  Acc: 80.000000\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.554438  Acc: 80.000000\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.564192  Acc: 79.000000\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.571347  Acc: 79.000000\n",
      "one epoch spend:  0:00:02.632749\n",
      "EPOCH:20, ACC:63.9\n",
      "\n",
      "CIFAR10 pytorch LeNet Train: EPOCH:20, BATCH_SZ:64, LR:0.01, ACC:65.81\n",
      "train spend time:  0:01:03.639476\n"
     ]
    }
   ],
   "source": [
    "# 如果不训练，直接加载保存的网络参数进行测试集验证\n",
    "if notrain:\n",
    "    net.load_state_dict(t.load(PARAS_FN))\n",
    "    net_test(net, test_load, 0)\n",
    "\n",
    "else:\n",
    "    optimizer = optim.SGD(net.parameters(), lr=trainlr, momentum=mm)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(1, ep + 1):\n",
    "        net_train(net, train_load, optimizer, epoch, logint)\n",
    "\n",
    "        # 每个epoch结束后用测试集检查识别准确度\n",
    "        net_test(net, test_load, epoch)\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "    global best_acc\n",
    "    #print('CIFAR10 pytorch LeNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(args.epochs, args.batch_size, lr, best_acc))\n",
    "    print('CIFAR10 pytorch LeNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(ep, bs, trainlr, best_acc))\n",
    "    print('train spend time: ', end_time - start_time)\n",
    "\n",
    "    if savemodel:\n",
    "        t.save(net.state_dict(), PARAS_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
