{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of Deep Learning for Computer Vision \n",
    "### Computer Vision and Machine Learning Research Group, Shenzhen University, 2019 Dec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Structure: AlexNet  \n",
    "Dataset: cifar-10 or ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referece: ImageNet Classification with Deep Convolutional Neural, Alex Krizhevsky, Sutskever, Ilya, Hinton, Geoffrey E, Advances in Neural Information Processing Systems 25, pp.1097--1105, 2012\n",
    "[Download Link](\n",
    "http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  \n",
    "\n",
    "Code is mostly based on:  \n",
    "https://www.cnblogs.com/zhengbiqing/p/10425503.html  contact：zhengbiqing 460356155@qq.com  \n",
    "and  \n",
    "https://blog.csdn.net/yychentracy/article/details/90256033  \n",
    "and  \n",
    "https://github.com/sloth2012/AlexNet/blob/master/AlexNet.ipynb\n",
    "  \n",
    "Dataset can be downloaded from:\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "# 样本读取线程数\n",
    "WORKERS = 4\n",
    "\n",
    "# 网络参赛保存文件名\n",
    "PARAS_FN = 'cifar_lenet_params.pkl'\n",
    "\n",
    "# minist数据存放位置\n",
    "#ROOT = '/home/szu-admin/local/data/cifar-10-100/cifar.10.py'\n",
    "ROOT = '/home/szu-admin/local/data/cifar-10/'\n",
    "# 目标函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最优结果\n",
    "best_acc = 0\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            # 卷积层1，3通道输入，96个卷积核，核大小7*7，步长2，填充2\n",
    "            # 经过该层图像大小变为32-7+2*2 / 2 +1，15*15\n",
    "            # 经3*3最大池化，2步长，图像变为15-3 / 2 + 1， 7*7\n",
    "            nn.Conv2d(3, 96, 7, 2, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 0),\n",
    "\n",
    "            # 卷积层2，96输入通道，256个卷积核，核大小5*5，步长1，填充2\n",
    "            # 经过该层图像变为7-5+2*2 / 1 + 1，7*7\n",
    "            # 经3*3最大池化，2步长，图像变为7-3 / 2 + 1， 3*3\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 0),\n",
    "\n",
    "            # 卷积层3，256输入通道，384个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 卷积层3，384输入通道，384个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            # 卷积层3，384输入通道，256个卷积核，核大小3*3，步长1，填充1\n",
    "            # 经过该层图像变为3-3+2*1 / 1 + 1，3*3\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            # 256个feature，每个feature 3*3\n",
    "            nn.Linear(256*3*3, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # x.size()[0]: batch size\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "'''\n",
    "训练并测试网络\n",
    "net：网络模型\n",
    "train_data_load：训练数据集\n",
    "optimizer：优化器\n",
    "epoch：第几次训练迭代\n",
    "log_interval：训练过程中损失函数值和准确率的打印频率\n",
    "'''\n",
    "def net_train(net, train_data_load, optimizer, epoch, log_interval):\n",
    "    net.train()\n",
    "\n",
    "    begin = datetime.datetime.now()\n",
    "\n",
    "    # 样本总数\n",
    "    total = len(train_data_load.dataset)\n",
    "\n",
    "    # 样本批次训练的损失函数值的和\n",
    "    train_loss = 0\n",
    "\n",
    "    # 识别正确的样本数\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(train_data_load, 0):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = net(img)\n",
    "        loss = loss_func(outs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失值和训练样本数\n",
    "        train_loss += loss.item()\n",
    "        # total += label.size(0)\n",
    "\n",
    "        _, predicted = t.max(outs.data, 1)\n",
    "        # 累加识别正确的样本数\n",
    "        ok += (predicted == label).sum()\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            # 训练结果输出\n",
    "\n",
    "            # 损失函数均值\n",
    "            loss_mean = train_loss / (i + 1)\n",
    "\n",
    "            # 已训练的样本数\n",
    "            traind_total = (i + 1) * len(label)\n",
    "\n",
    "            # 准确度\n",
    "            acc = 100. * ok / traind_total\n",
    "\n",
    "            # 一个迭代的进度百分比\n",
    "            progress = 100. * traind_total / total\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}  Acc: {:.6f}'.format(\n",
    "                epoch, traind_total, total, progress, loss_mean, acc))\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('one epoch spend: ', end - begin)\n",
    "\n",
    "\n",
    "'''\n",
    "用测试集检查准确率\n",
    "'''\n",
    "def net_test(net, test_data_load, epoch):\n",
    "    net.eval()\n",
    "\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(test_data_load):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        outs = net(img)\n",
    "        _, pre = t.max(outs.data, 1)\n",
    "        ok += (pre == label).sum()\n",
    "\n",
    "    acc = ok.item() * 100. / (len(test_data_load.dataset))\n",
    "    print('EPOCH:{}, ACC:{}\\n'.format(epoch, acc))\n",
    "\n",
    "    global best_acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "'''\n",
    "显示数据集中一个图片\n",
    "'''\n",
    "def img_show(dataset, index):\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    show = ToPILImage()\n",
    "\n",
    "    data, label = dataset[index]\n",
    "    print('img is a ', classes[label])\n",
    "    show((data + 1) / 2).resize((100, 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='PyTorch CIFA10 LeNet Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数设置，可通过命令行设置\n",
    "bs = 64            # batch-size\n",
    "testbs = 1000      # test-batch-size\n",
    "ep = 20            # epochs \n",
    "trainlr = 0.01     # learning rate (default: 0.01)\n",
    "mm = 0.9           # SGD momentum (default: 0.9)\n",
    "logint = 100       # log-interval\n",
    "notrain = False    # If train the Model\n",
    "savemodel = False  # For Saving the current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数值转换，ToTensor源码注释\n",
    "\"\"\"\n",
    "Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "[0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "\"\"\"\n",
    "# 归一化把[0.0, 1.0]变换为[-1,1], ([0, 1] - 0.5) / 0.5 = [-1, 1]\n",
    "transform = tv.transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "# 定义数据集\n",
    "#train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=True, transform=transform)\n",
    "train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=False, transform=transform)\n",
    "test_data = tv.datasets.CIFAR10(root=ROOT, train=False, download=False, transform=transform)\n",
    "\n",
    "train_load = t.utils.data.DataLoader(train_data, batch_size=bs, shuffle=True, num_workers=WORKERS)\n",
    "test_load = t.utils.data.DataLoader(test_data, batch_size=testbs, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff5d55b4a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 看一下数据中的等待分类的图片\n",
    "from PIL import Image\n",
    "import sys\n",
    "#im = Image.open(train_data[5][0])\n",
    "im = Image.fromarray(train_data.data[5][:])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2304, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define AlexNet\n",
    "net = AlexNet().cuda()\n",
    "# print network structure\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.302870  Acc: 10.000000\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.302757  Acc: 10.000000\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.301993  Acc: 10.000000\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.299688  Acc: 11.000000\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.266000  Acc: 12.000000\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.218571  Acc: 13.000000\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.174436  Acc: 15.000000\n",
      "one epoch spend:  0:00:06.170923\n",
      "EPOCH:1, ACC:28.91\n",
      "\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.779500  Acc: 28.000000\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.751278  Acc: 30.000000\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.726702  Acc: 31.000000\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.710484  Acc: 32.000000\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.684233  Acc: 33.000000\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.660880  Acc: 34.000000\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.637992  Acc: 35.000000\n",
      "one epoch spend:  0:00:06.005720\n",
      "EPOCH:2, ACC:47.2\n",
      "\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.385359  Acc: 47.000000\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.356107  Acc: 48.000000\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.333535  Acc: 49.000000\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.306938  Acc: 51.000000\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.295345  Acc: 51.000000\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.281787  Acc: 52.000000\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.265957  Acc: 53.000000\n",
      "one epoch spend:  0:00:06.056027\n",
      "EPOCH:3, ACC:57.5\n",
      "\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.105647  Acc: 60.000000\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.090317  Acc: 60.000000\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.085503  Acc: 60.000000\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.075609  Acc: 61.000000\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.059871  Acc: 62.000000\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.050677  Acc: 62.000000\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.040643  Acc: 62.000000\n",
      "one epoch spend:  0:00:06.002798\n",
      "EPOCH:4, ACC:64.42\n",
      "\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.890231  Acc: 68.000000\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.891945  Acc: 68.000000\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.895997  Acc: 68.000000\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.892990  Acc: 68.000000\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.890069  Acc: 68.000000\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.889379  Acc: 68.000000\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.884255  Acc: 68.000000\n",
      "one epoch spend:  0:00:05.932731\n",
      "EPOCH:5, ACC:66.11\n",
      "\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.784059  Acc: 72.000000\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.777103  Acc: 72.000000\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.770424  Acc: 72.000000\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.772318  Acc: 72.000000\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.773680  Acc: 72.000000\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.771334  Acc: 73.000000\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.768074  Acc: 73.000000\n",
      "one epoch spend:  0:00:05.940216\n",
      "EPOCH:6, ACC:70.26\n",
      "\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.631319  Acc: 77.000000\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.632264  Acc: 77.000000\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.644350  Acc: 77.000000\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.649976  Acc: 77.000000\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.651679  Acc: 77.000000\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.659199  Acc: 77.000000\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.657558  Acc: 77.000000\n",
      "one epoch spend:  0:00:05.895422\n",
      "EPOCH:7, ACC:72.92\n",
      "\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.552056  Acc: 81.000000\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.549535  Acc: 80.000000\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.546025  Acc: 81.000000\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.552558  Acc: 80.000000\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.551963  Acc: 81.000000\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.559413  Acc: 80.000000\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.561749  Acc: 80.000000\n",
      "one epoch spend:  0:00:05.829414\n",
      "EPOCH:8, ACC:74.2\n",
      "\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.428714  Acc: 85.000000\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.454131  Acc: 84.000000\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.456610  Acc: 84.000000\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.468462  Acc: 83.000000\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.476375  Acc: 83.000000\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.481569  Acc: 83.000000\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.480914  Acc: 83.000000\n",
      "one epoch spend:  0:00:05.880116\n",
      "EPOCH:9, ACC:73.96\n",
      "\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.369542  Acc: 86.000000\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.372763  Acc: 87.000000\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.387997  Acc: 86.000000\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.388481  Acc: 86.000000\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.390792  Acc: 86.000000\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.399331  Acc: 86.000000\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.408435  Acc: 85.000000\n",
      "one epoch spend:  0:00:05.959356\n",
      "EPOCH:10, ACC:73.94\n",
      "\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.318648  Acc: 88.000000\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.314763  Acc: 88.000000\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.321351  Acc: 88.000000\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.323750  Acc: 88.000000\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.326810  Acc: 88.000000\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.333706  Acc: 88.000000\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.335529  Acc: 88.000000\n",
      "one epoch spend:  0:00:05.853000\n",
      "EPOCH:11, ACC:74.26\n",
      "\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.274157  Acc: 90.000000\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.262703  Acc: 91.000000\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.265788  Acc: 90.000000\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.269654  Acc: 90.000000\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.273561  Acc: 90.000000\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.275650  Acc: 90.000000\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.280336  Acc: 90.000000\n",
      "one epoch spend:  0:00:05.854004\n",
      "EPOCH:12, ACC:74.47\n",
      "\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.201874  Acc: 93.000000\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.204448  Acc: 92.000000\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.213626  Acc: 92.000000\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.220637  Acc: 92.000000\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.223980  Acc: 92.000000\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.224799  Acc: 92.000000\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.229859  Acc: 91.000000\n",
      "one epoch spend:  0:00:05.846959\n",
      "EPOCH:13, ACC:75.06\n",
      "\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.184917  Acc: 93.000000\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.184031  Acc: 93.000000\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.189041  Acc: 93.000000\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.189023  Acc: 93.000000\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.194969  Acc: 93.000000\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.196067  Acc: 93.000000\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.197739  Acc: 92.000000\n",
      "one epoch spend:  0:00:05.856013\n",
      "EPOCH:14, ACC:74.71\n",
      "\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.171962  Acc: 93.000000\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.158167  Acc: 94.000000\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.156808  Acc: 94.000000\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.156822  Acc: 94.000000\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.158449  Acc: 94.000000\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.167389  Acc: 94.000000\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.170048  Acc: 94.000000\n",
      "one epoch spend:  0:00:05.864532\n",
      "EPOCH:15, ACC:75.29\n",
      "\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.098717  Acc: 96.000000\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.128384  Acc: 95.000000\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.128589  Acc: 95.000000\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.130426  Acc: 95.000000\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.135274  Acc: 95.000000\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.136319  Acc: 95.000000\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.136443  Acc: 95.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one epoch spend:  0:00:05.861040\n",
      "EPOCH:16, ACC:75.74\n",
      "\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.089274  Acc: 97.000000\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.104611  Acc: 96.000000\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.112496  Acc: 96.000000\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.113485  Acc: 96.000000\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.113845  Acc: 96.000000\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.116079  Acc: 95.000000\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.117045  Acc: 95.000000\n",
      "one epoch spend:  0:00:05.846890\n",
      "EPOCH:17, ACC:75.49\n",
      "\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.082743  Acc: 97.000000\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.081406  Acc: 97.000000\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.085588  Acc: 97.000000\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.087680  Acc: 97.000000\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.091854  Acc: 96.000000\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.096048  Acc: 96.000000\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.101357  Acc: 96.000000\n",
      "one epoch spend:  0:00:05.957541\n",
      "EPOCH:18, ACC:76.51\n",
      "\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.059621  Acc: 97.000000\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.069896  Acc: 97.000000\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.077892  Acc: 97.000000\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.082708  Acc: 97.000000\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.081460  Acc: 97.000000\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.083221  Acc: 97.000000\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.084834  Acc: 97.000000\n",
      "one epoch spend:  0:00:05.841432\n",
      "EPOCH:19, ACC:75.55\n",
      "\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.055910  Acc: 98.000000\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.059502  Acc: 97.000000\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.068875  Acc: 97.000000\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.075285  Acc: 97.000000\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.073621  Acc: 97.000000\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.073586  Acc: 97.000000\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.074773  Acc: 97.000000\n",
      "one epoch spend:  0:00:05.878168\n",
      "EPOCH:20, ACC:76.05\n",
      "\n",
      "CIFAR10 pytorch AlexNet Train: EPOCH:20, BATCH_SZ:64, LR:0.01, ACC:76.51\n",
      "train spend time:  0:02:09.544519\n"
     ]
    }
   ],
   "source": [
    "# 如果不训练，直接加载保存的网络参数进行测试集验证\n",
    "if notrain:\n",
    "    net.load_state_dict(t.load(PARAS_FN))\n",
    "    net_test(net, test_load, 0)\n",
    "\n",
    "else:\n",
    "    optimizer = optim.SGD(net.parameters(), lr=trainlr, momentum=mm)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(1, ep + 1):\n",
    "        net_train(net, train_load, optimizer, epoch, logint)\n",
    "\n",
    "        # 每个epoch结束后用测试集检查识别准确度\n",
    "        net_test(net, test_load, epoch)\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "    global best_acc\n",
    "    #print('CIFAR10 pytorch LeNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(args.epochs, args.batch_size, lr, best_acc))\n",
    "    print('CIFAR10 pytorch AlexNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(ep, bs, trainlr, best_acc))\n",
    "    print('train spend time: ', end_time - start_time)\n",
    "\n",
    "    if savemodel:\n",
    "        t.save(net.state_dict(), PARAS_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
