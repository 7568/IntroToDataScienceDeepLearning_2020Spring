{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of Deep Learning for Computer Vision \n",
    "### Computer Vision and Machine Learning Research Group, Shenzhen University, 2019 Dec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Structure: LeNet  \n",
    "Dataset: cifar-10 or ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Szegedy et al., \"Going deeper with convolutions,\" 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, 2015, pp. 1-9.\n",
    "[Download Link](\n",
    "https://arxiv.org/pdf/1409.4842v1.pdf)  \n",
    "\n",
    "Code is mostly based on:  \n",
    "https://www.cnblogs.com/zhengbiqing/p/10425811.html contact：zhengbiqing 460356155@qq.com  \n",
    "\n",
    "Dataset can be downloaded from:\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "# 样本读取线程数\n",
    "WORKERS = 4\n",
    "\n",
    "# 网络参赛保存文件名\n",
    "PARAS_FN = 'cifar_lenet_params.pkl'\n",
    "\n",
    "# minist数据存放位置\n",
    "ROOT = '/home/zbq/PycharmProjects/cifar'\n",
    "ROOT = '/home/szu-admin/local/data/cifar-10-100/cifar.10.py'\n",
    "\n",
    "# 目标函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最优结果\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "创建VGG块\n",
    "参数分别为输入通道数，输出通道数，卷积层个数，是否做最大池化\n",
    "'''\n",
    "def make_vgg_block(in_channel, out_channel, convs, pool=True):\n",
    "    net = []\n",
    "\n",
    "    # 不改变图片尺寸卷积\n",
    "    net.append(nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1))\n",
    "    net.append(nn.BatchNorm2d(out_channel))\n",
    "    net.append(nn.ReLU(inplace=True))\n",
    "\n",
    "    for i in range(convs - 1):\n",
    "        # 不改变图片尺寸卷积\n",
    "        net.append(nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1))\n",
    "        net.append(nn.BatchNorm2d(out_channel))\n",
    "        net.append(nn.ReLU(inplace=True))\n",
    "\n",
    "    if pool:\n",
    "        # 2*2最大池化，图片变为w/2 * h/2\n",
    "        net.append(nn.MaxPool2d(2))\n",
    "\n",
    "    return nn.Sequential(*net)\n",
    "\n",
    "\n",
    "# 定义网络模型\n",
    "class VGG19Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG19Net, self).__init__()\n",
    "\n",
    "        net = []\n",
    "\n",
    "        # 输入32*32，输出16*16\n",
    "        net.append(make_vgg_block(3, 64, 2))\n",
    "\n",
    "        # 输出8*8\n",
    "        net.append(make_vgg_block(64, 128, 2))\n",
    "\n",
    "        # 输出4*4\n",
    "        net.append(make_vgg_block(128, 256, 4))\n",
    "\n",
    "        # 输出2*2\n",
    "        net.append(make_vgg_block(256, 512, 4))\n",
    "\n",
    "        # 无池化层，输出保持2*2\n",
    "        net.append(make_vgg_block(512, 512, 4, False))\n",
    "\n",
    "        self.cnn = nn.Sequential(*net)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            # 512个feature，每个feature 2*2\n",
    "            nn.Linear(512*2*2, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "\n",
    "        # x.size()[0]: batch size\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "训练并测试网络\n",
    "net：网络模型\n",
    "train_data_load：训练数据集\n",
    "optimizer：优化器\n",
    "epoch：第几次训练迭代\n",
    "log_interval：训练过程中损失函数值和准确率的打印频率\n",
    "'''\n",
    "def net_train(net, train_data_load, optimizer, epoch, log_interval):\n",
    "    net.train()\n",
    "\n",
    "    begin = datetime.datetime.now()\n",
    "\n",
    "    # 样本总数\n",
    "    total = len(train_data_load.dataset)\n",
    "\n",
    "    # 样本批次训练的损失函数值的和\n",
    "    train_loss = 0\n",
    "\n",
    "    # 识别正确的样本数\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(train_data_load, 0):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = net(img)\n",
    "        loss = loss_func(outs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累加损失值和训练样本数\n",
    "        train_loss += loss.item()\n",
    "        # total += label.size(0)\n",
    "\n",
    "        _, predicted = t.max(outs.data, 1)\n",
    "        # 累加识别正确的样本数\n",
    "        ok += (predicted == label).sum()\n",
    "\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            # 训练结果输出\n",
    "\n",
    "            # 损失函数均值\n",
    "            loss_mean = train_loss / (i + 1)\n",
    "\n",
    "            # 已训练的样本数\n",
    "            traind_total = (i + 1) * len(label)\n",
    "\n",
    "            # 准确度\n",
    "            acc = 100. * ok / traind_total\n",
    "\n",
    "            # 一个迭代的进度百分比\n",
    "            progress = 100. * traind_total / total\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}  Acc: {:.6f}'.format(\n",
    "                epoch, traind_total, total, progress, loss_mean, acc))\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    print('one epoch spend: ', end - begin)\n",
    "\n",
    "\n",
    "'''\n",
    "用测试集检查准确率\n",
    "'''\n",
    "def net_test(net, test_data_load, epoch):\n",
    "    net.eval()\n",
    "\n",
    "    ok = 0\n",
    "\n",
    "    for i, data in enumerate(test_data_load):\n",
    "        img, label = data\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        outs = net(img)\n",
    "        _, pre = t.max(outs.data, 1)\n",
    "        ok += (pre == label).sum()\n",
    "\n",
    "    acc = ok.item() * 100. / (len(test_data_load.dataset))\n",
    "    print('EPOCH:{}, ACC:{}\\n'.format(epoch, acc))\n",
    "\n",
    "    global best_acc\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "\n",
    "\n",
    "'''\n",
    "显示数据集中一个图片\n",
    "'''\n",
    "def img_show(dataset, index):\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    show = ToPILImage()\n",
    "\n",
    "    data, label = dataset[index]\n",
    "    print('img is a ', classes[label])\n",
    "    show((data + 1) / 2).resize((100, 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parser = argparse.ArgumentParser(description='PyTorch CIFA10 LeNet Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数设置，可通过命令行设置\n",
    "bs = 64            # batch-size\n",
    "testbs = 1000      # test-batch-size\n",
    "ep = 20            # epochs \n",
    "trainlr = 0.01     # learning rate (default: 0.01)\n",
    "mm = 0.9           # SGD momentum (default: 0.9)\n",
    "logint = 100       # logging-interval\n",
    "notrain = False    # If train the Model\n",
    "savemodel = False  # For Saving the current Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数值转换，ToTensor源码注释\n",
    "\"\"\"\n",
    "Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
    "Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n",
    "[0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n",
    "\"\"\"\n",
    "# 归一化把[0.0, 1.0]变换为[-1,1], ([0, 1] - 0.5) / 0.5 = [-1, 1]\n",
    "transform = tv.transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "# 定义数据集\n",
    "#train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=True, transform=transform)\n",
    "train_data = tv.datasets.CIFAR10(root=ROOT, train=True, download=False, transform=transform)\n",
    "test_data = tv.datasets.CIFAR10(root=ROOT, train=False, download=False, transform=transform)\n",
    "\n",
    "train_load = t.utils.data.DataLoader(train_data, batch_size=bs, shuffle=True, num_workers=WORKERS)\n",
    "test_load = t.utils.data.DataLoader(test_data, batch_size=testbs, shuffle=False, num_workers=WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa8c0648b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 看一下数据中的等待分类的图片\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import sys\n",
    "#im = Image.open(train_data.data[5][0])\n",
    "im = Image.fromarray(train_data.data[5][:])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2471,  0.1765,  0.2000,  ..., -0.2863, -0.4196, -0.4039],\n",
       "          [ 0.1137,  0.1451,  0.2157,  ..., -0.0039, -0.0431, -0.3255],\n",
       "          [-0.1451, -0.2235, -0.1765,  ...,  0.0745,  0.2784, -0.2706],\n",
       "          ...,\n",
       "          [ 0.9137,  0.8824,  0.8902,  ...,  0.2235,  0.4039,  0.5686],\n",
       "          [ 0.9294,  0.9059,  0.9059,  ...,  0.2706,  0.3961,  0.5059],\n",
       "          [ 0.9294,  0.9059,  0.9137,  ...,  0.3020,  0.3569,  0.4275]],\n",
       " \n",
       "         [[-0.2000, -0.2863, -0.2549,  ..., -0.4431, -0.5059, -0.5451],\n",
       "          [-0.4118, -0.4353, -0.4039,  ..., -0.1765, -0.1294, -0.4588],\n",
       "          [-0.4745, -0.5451, -0.5373,  ..., -0.1216,  0.0353, -0.4353],\n",
       "          ...,\n",
       "          [ 0.0118, -0.0353, -0.0431,  ..., -0.6706, -0.5373, -0.4275],\n",
       "          [ 0.0431,  0.0039, -0.0039,  ..., -0.6549, -0.5608, -0.4902],\n",
       "          [ 0.0902,  0.0431,  0.0353,  ..., -0.6314, -0.6000, -0.5529]],\n",
       " \n",
       "         [[-0.2078, -0.2549, -0.2392,  ..., -0.5608, -0.5686, -0.5686],\n",
       "          [-0.4667, -0.4824, -0.4902,  ..., -0.4431, -0.2706, -0.5216],\n",
       "          [-0.4118, -0.5294, -0.5922,  ..., -0.3725, -0.1765, -0.4431],\n",
       "          ...,\n",
       "          [-0.4510, -0.4902, -0.4902,  ..., -0.8824, -0.7961, -0.7176],\n",
       "          [-0.4196, -0.4353, -0.4510,  ..., -0.8902, -0.8275, -0.7882],\n",
       "          [-0.3569, -0.3882, -0.3961,  ..., -0.8902, -0.8667, -0.8510]]]), 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[5][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19Net(\n",
      "  (cnn): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace)\n",
      "      (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace)\n",
      "      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace)\n",
      "      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace)\n",
      "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(inplace)\n",
      "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define LeNet\n",
    "net = VGG19Net().cuda()\n",
    "# print network structure\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.957954  Acc: 23.000000\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.822127  Acc: 29.000000\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.736716  Acc: 32.000000\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.668329  Acc: 35.000000\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.614789  Acc: 38.000000\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.560977  Acc: 40.000000\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.515182  Acc: 42.000000\n",
      "one epoch spend:  0:00:52.329624\n",
      "EPOCH:1, ACC:58.17\n",
      "\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.113011  Acc: 60.000000\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.088249  Acc: 61.000000\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.056068  Acc: 62.000000\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.041656  Acc: 63.000000\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.025482  Acc: 64.000000\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.010425  Acc: 64.000000\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.993115  Acc: 65.000000\n",
      "one epoch spend:  0:00:51.644704\n",
      "EPOCH:2, ACC:70.3\n",
      "\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.804854  Acc: 72.000000\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.795814  Acc: 72.000000\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.803231  Acc: 72.000000\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.795561  Acc: 72.000000\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.788204  Acc: 73.000000\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.777020  Acc: 73.000000\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.769266  Acc: 73.000000\n",
      "one epoch spend:  0:00:51.673284\n",
      "EPOCH:3, ACC:73.9\n",
      "\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.630332  Acc: 78.000000\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.631665  Acc: 78.000000\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.621748  Acc: 79.000000\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.621613  Acc: 79.000000\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.622611  Acc: 79.000000\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.618064  Acc: 79.000000\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.615689  Acc: 79.000000\n",
      "one epoch spend:  0:00:51.496701\n",
      "EPOCH:4, ACC:74.86\n",
      "\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.514911  Acc: 83.000000\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.508323  Acc: 83.000000\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.520401  Acc: 82.000000\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.522227  Acc: 82.000000\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.526077  Acc: 82.000000\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.526844  Acc: 82.000000\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.524400  Acc: 82.000000\n",
      "one epoch spend:  0:00:51.490624\n",
      "EPOCH:5, ACC:78.32\n",
      "\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.432599  Acc: 85.000000\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.431215  Acc: 85.000000\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.431511  Acc: 85.000000\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.435984  Acc: 85.000000\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.437268  Acc: 85.000000\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.438339  Acc: 85.000000\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.440413  Acc: 85.000000\n",
      "one epoch spend:  0:00:51.496755\n",
      "EPOCH:6, ACC:79.09\n",
      "\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.368794  Acc: 87.000000\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.367830  Acc: 87.000000\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.370382  Acc: 87.000000\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.374932  Acc: 87.000000\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.374372  Acc: 87.000000\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.374093  Acc: 87.000000\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.373416  Acc: 87.000000\n",
      "one epoch spend:  0:00:51.504806\n",
      "EPOCH:7, ACC:81.02\n",
      "\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.291227  Acc: 90.000000\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.304438  Acc: 89.000000\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.307709  Acc: 89.000000\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.309043  Acc: 89.000000\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.307059  Acc: 89.000000\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.308320  Acc: 89.000000\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.308364  Acc: 89.000000\n",
      "one epoch spend:  0:00:51.492587\n",
      "EPOCH:8, ACC:82.36\n",
      "\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.234469  Acc: 92.000000\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.256081  Acc: 91.000000\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.256934  Acc: 91.000000\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.259334  Acc: 91.000000\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.261762  Acc: 91.000000\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.262458  Acc: 91.000000\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.262692  Acc: 91.000000\n",
      "one epoch spend:  0:00:51.639901\n",
      "EPOCH:9, ACC:82.1\n",
      "\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.230339  Acc: 92.000000\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.223776  Acc: 92.000000\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.223583  Acc: 92.000000\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.219420  Acc: 92.000000\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.225230  Acc: 92.000000\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.227143  Acc: 92.000000\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.232131  Acc: 92.000000\n",
      "one epoch spend:  0:00:51.486338\n",
      "EPOCH:10, ACC:82.74\n",
      "\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.168679  Acc: 94.000000\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.163242  Acc: 94.000000\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.180283  Acc: 94.000000\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.178153  Acc: 94.000000\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.179273  Acc: 94.000000\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.180821  Acc: 94.000000\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.185339  Acc: 93.000000\n",
      "one epoch spend:  0:00:52.972651\n",
      "EPOCH:11, ACC:83.53\n",
      "\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.156715  Acc: 94.000000\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.155920  Acc: 94.000000\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.158620  Acc: 94.000000\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.159207  Acc: 94.000000\n",
      "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.159561  Acc: 94.000000\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.160758  Acc: 94.000000\n",
      "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.162488  Acc: 94.000000\n",
      "one epoch spend:  0:00:54.042487\n",
      "EPOCH:12, ACC:81.6\n",
      "\n",
      "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.132854  Acc: 95.000000\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.136194  Acc: 95.000000\n",
      "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.136961  Acc: 95.000000\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.133900  Acc: 95.000000\n",
      "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.134823  Acc: 95.000000\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.136834  Acc: 95.000000\n",
      "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.138276  Acc: 95.000000\n",
      "one epoch spend:  0:00:52.227750\n",
      "EPOCH:13, ACC:83.99\n",
      "\n",
      "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.100220  Acc: 96.000000\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.103623  Acc: 96.000000\n",
      "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.114810  Acc: 96.000000\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.115398  Acc: 96.000000\n",
      "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.114964  Acc: 96.000000\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.117932  Acc: 96.000000\n",
      "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.118385  Acc: 96.000000\n",
      "one epoch spend:  0:00:51.339874\n",
      "EPOCH:14, ACC:82.79\n",
      "\n",
      "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.092912  Acc: 97.000000\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.088414  Acc: 97.000000\n",
      "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.096382  Acc: 96.000000\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.100690  Acc: 96.000000\n",
      "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.099429  Acc: 96.000000\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.098216  Acc: 96.000000\n",
      "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.099945  Acc: 96.000000\n",
      "one epoch spend:  0:00:51.330958\n",
      "EPOCH:15, ACC:82.99\n",
      "\n",
      "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.080564  Acc: 97.000000\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.077742  Acc: 97.000000\n",
      "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.079689  Acc: 97.000000\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.081046  Acc: 97.000000\n",
      "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.082033  Acc: 97.000000\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.081465  Acc: 97.000000\n",
      "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.081822  Acc: 97.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one epoch spend:  0:00:51.352622\n",
      "EPOCH:16, ACC:84.95\n",
      "\n",
      "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.070733  Acc: 97.000000\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.064635  Acc: 97.000000\n",
      "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.070918  Acc: 97.000000\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.074762  Acc: 97.000000\n",
      "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.076548  Acc: 97.000000\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.075248  Acc: 97.000000\n",
      "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.074238  Acc: 97.000000\n",
      "one epoch spend:  0:00:51.335060\n",
      "EPOCH:17, ACC:84.91\n",
      "\n",
      "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.053149  Acc: 98.000000\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.054495  Acc: 97.000000\n",
      "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.051650  Acc: 98.000000\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.057129  Acc: 98.000000\n",
      "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.061798  Acc: 97.000000\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.061933  Acc: 97.000000\n",
      "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.062075  Acc: 97.000000\n",
      "one epoch spend:  0:00:51.328571\n",
      "EPOCH:18, ACC:84.88\n",
      "\n",
      "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.034146  Acc: 98.000000\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.046974  Acc: 98.000000\n",
      "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.053850  Acc: 98.000000\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.054677  Acc: 98.000000\n",
      "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.056623  Acc: 98.000000\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.056175  Acc: 98.000000\n",
      "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.055537  Acc: 98.000000\n",
      "one epoch spend:  0:00:51.326952\n",
      "EPOCH:19, ACC:84.6\n",
      "\n",
      "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.051187  Acc: 98.000000\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.056823  Acc: 97.000000\n",
      "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.056834  Acc: 98.000000\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.054600  Acc: 98.000000\n",
      "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.051645  Acc: 98.000000\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.052006  Acc: 98.000000\n",
      "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.053820  Acc: 98.000000\n",
      "one epoch spend:  0:00:51.324405\n",
      "EPOCH:20, ACC:85.09\n",
      "\n",
      "CIFAR10 pytorch VGG Train: EPOCH:20, BATCH_SZ:64, LR:0.01, ACC:85.09\n",
      "train spend time:  0:17:41.253863\n"
     ]
    }
   ],
   "source": [
    "# 如果不训练，直接加载保存的网络参数进行测试集验证\n",
    "if notrain:\n",
    "    net.load_state_dict(t.load(PARAS_FN))\n",
    "    net_test(net, test_load, 0)\n",
    "\n",
    "else:\n",
    "    optimizer = optim.SGD(net.parameters(), lr=trainlr, momentum=mm)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(1, ep + 1):\n",
    "        net_train(net, train_load, optimizer, epoch, logint)\n",
    "\n",
    "        # 每个epoch结束后用测试集检查识别准确度\n",
    "        net_test(net, test_load, epoch)\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "    global best_acc\n",
    "    #print('CIFAR10 pytorch LeNet Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(args.epochs, args.batch_size, lr, best_acc))\n",
    "    print('CIFAR10 pytorch VGG Train: EPOCH:{}, BATCH_SZ:{}, LR:{}, ACC:{}'.format(ep, bs, trainlr, best_acc))\n",
    "    print('train spend time: ', end_time - start_time)\n",
    "\n",
    "    if savemodel:\n",
    "        t.save(net.state_dict(), PARAS_FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
